{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_sales_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>sales</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_cnt_month_diff</th>\n",
       "      <th>item_cnt_day_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10242.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7501.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9685.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>598.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>598.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950661</th>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9053.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950662</th>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14755.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950663</th>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950664</th>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21652.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950665</th>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950666 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  year  month  date_block_num  shop_id  item_id  item_price  \\\n",
       "0       2013-01-01  2013    1.0             0.0     15.0   2308.0       799.0   \n",
       "1       2013-01-01  2013    1.0             0.0     18.0  10242.0       249.0   \n",
       "2       2013-01-01  2013    1.0             0.0     51.0   7501.0       285.0   \n",
       "3       2013-01-01  2013    1.0             0.0     18.0   9685.0        58.0   \n",
       "4       2013-01-01  2013    1.0             0.0     19.0   1894.0       598.5   \n",
       "...            ...   ...    ...             ...      ...      ...         ...   \n",
       "950661  2013-12-15  2013   12.0            11.0     31.0   9053.0       249.0   \n",
       "950662  2013-12-15  2013   12.0            11.0     58.0  14755.0       149.0   \n",
       "950663  2013-12-15  2013   12.0            11.0     58.0   1523.0       799.0   \n",
       "950664  2013-12-15  2013   12.0            11.0      5.0  21652.0       499.0   \n",
       "950665  2013-12-15  2013    NaN             NaN      NaN      NaN         NaN   \n",
       "\n",
       "        item_cnt_day  sales  item_cnt_month  item_cnt_month_diff  \\\n",
       "0                1.0  799.0             8.0                  NaN   \n",
       "1                1.0  249.0             4.0                 -4.0   \n",
       "2                1.0  285.0             2.0                 -2.0   \n",
       "3                1.0   58.0             1.0                 -1.0   \n",
       "4                1.0  598.5             1.0                  0.0   \n",
       "...              ...    ...             ...                  ...   \n",
       "950661           1.0  249.0             2.0                 -2.0   \n",
       "950662           1.0  149.0             8.0                  6.0   \n",
       "950663           1.0  799.0             2.0                 -6.0   \n",
       "950664           1.0  499.0             1.0                 -1.0   \n",
       "950665           NaN    NaN             NaN                  NaN   \n",
       "\n",
       "        item_cnt_day_diff  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "...                   ...  \n",
       "950661             -523.0  \n",
       "950662             -523.0  \n",
       "950663             -523.0  \n",
       "950664             -523.0  \n",
       "950665                NaN  \n",
       "\n",
       "[950666 rows x 12 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the 'item_cnt_day_diff' and 'item_cnt_month_diff' columns\n",
    "df_clean = df.dropna(subset=['item_cnt_day_diff', 'item_cnt_month_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948964, 12)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>sales</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_cnt_month_diff</th>\n",
       "      <th>item_cnt_day_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19369.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18783.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>19366.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>19154.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3889.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  year  month  date_block_num  shop_id  item_id  item_price  \\\n",
       "1354  2013-01-02  2013    1.0             0.0     54.0   2820.0       349.0   \n",
       "1355  2013-01-02  2013    1.0             0.0     25.0  19369.0       549.0   \n",
       "1356  2013-01-02  2013    1.0             0.0     56.0  18783.0       179.0   \n",
       "1357  2013-01-02  2013    1.0             0.0     56.0  19366.0       399.0   \n",
       "1358  2013-01-02  2013    1.0             0.0     56.0  19154.0       199.0   \n",
       "\n",
       "      item_cnt_day  sales  item_cnt_month  item_cnt_month_diff  \\\n",
       "1354           1.0  349.0             2.0                  0.0   \n",
       "1355           1.0  549.0             6.0                  4.0   \n",
       "1356           1.0  179.0             2.0                 -4.0   \n",
       "1357           1.0  399.0             2.0                  0.0   \n",
       "1358           1.0  199.0             2.0                  0.0   \n",
       "\n",
       "      item_cnt_day_diff  \n",
       "1354             3889.0  \n",
       "1355             3889.0  \n",
       "1356             3889.0  \n",
       "1357             3889.0  \n",
       "1358             3889.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (664275, 12)\n",
      "Validation shape: (94896, 12)\n",
      "Test shape: (189793, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split based on time (for example, 80% for training, 20% for testing)\n",
    "train_size = int(len(df_clean) * 0.8)\n",
    "\n",
    "# Split the data\n",
    "train = df_clean[:train_size]\n",
    "test = df_clean[train_size:]\n",
    "\n",
    "# You can also further split the training data into training and validation sets (e.g., 70-10-20 split)\n",
    "validation_size = int(len(train) * 0.125)  # 10% of the total dataset\n",
    "validation = train[-validation_size:]\n",
    "train = train[:-validation_size]\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Validation shape:\", validation.shape)\n",
    "print(\"Test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'year', 'month', 'date_block_num', 'shop_id', 'item_id',\n",
       "       'item_price', 'item_cnt_day', 'sales', 'item_cnt_month',\n",
       "       'item_cnt_month_diff', 'item_cnt_day_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering -- Target : Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78328, 11) (111, 11) (4239, 11)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - creating lag features\n",
    "def create_lag_features(df, target_column, lags=[1, 2, 3, 6, 12]):\n",
    "    \"\"\"\n",
    "    Creates lag features for a given target column.\n",
    "    \"\"\"\n",
    "    for lag in lags:\n",
    "        df[f'{target_column}_lag_{lag}'] = df.groupby(['shop_id', 'item_id'])[target_column].shift(lag)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply lag features for 'item_cnt_month_diff' and 'item_cnt_day_diff'\n",
    "train = create_lag_features(train, 'item_cnt_month_diff')\n",
    "validation = create_lag_features(validation, 'item_cnt_month_diff')\n",
    "test = create_lag_features(test, 'item_cnt_month_diff')\n",
    "\n",
    "# Features for the model\n",
    "features = ['year', 'month', 'date_block_num', 'shop_id', 'item_id', 'item_price'] + \\\n",
    "           [f'item_cnt_month_diff_lag_{lag}' for lag in [1, 2, 3, 6, 12]]\n",
    "\n",
    "# Targets\n",
    "target = 'item_cnt_month_diff'\n",
    "\n",
    "# Define X and y for training, validation, and test datasets\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = validation[features]\n",
    "y_val = validation[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify the shapes after scaling\n",
    "print(X_train_scaled.shape, X_val_scaled.shape, X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Experiments & Modeling with MLflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tracking URI for MLflow\n",
    "mlflow.set_tracking_uri(\"../mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/ilyeslenoob/Sales-Prediction-with-Deep-Learning/notebooks/../mlruns/0', creation_time=1732936617013, experiment_id='0', last_update_time=1732938747944, lifecycle_stage='active', name='SALES EXP Monthly', tags={}>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_id=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 18:04:14 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.4.2 <= xgboost <= 2.1.2, but the installed version is 2.1.3. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n",
      "2024/11/30 18:04:14 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    }
   ],
   "source": [
    "# Enable MLflow autologging for sklearn and XGBoost models\n",
    "mlflow.sklearn.autolog()\n",
    "mlflow.xgboost.autolog()\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log_model(model, model_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Create a custom run name by combining the model name and current date\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()  # Start time before training the model\n",
    "    \n",
    "    # Start MLflow run with a custom name\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        \n",
    "        # Calculate RMSE for train and validation sets\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "        # Calculate RMSE for test set\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        \n",
    "        # Calculate the elapsed time in seconds\n",
    "        elapsed_time = time.time() - start_time  # End time - start time\n",
    "        \n",
    "        # Log parameters, metrics, and elapsed time to MLflow\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        mlflow.log_metric('train_rmse', train_rmse)\n",
    "        mlflow.log_metric('val_rmse', val_rmse)\n",
    "        mlflow.log_metric('test_rmse', test_rmse)\n",
    "        mlflow.log_metric('elapsed_time', elapsed_time)  # Log elapsed time as a metric\n",
    "        \n",
    "        # Log the model (MLflow autologging will automatically log the model too)\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        return val_rmse  # Return validation RMSE for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define basic models\n",
    "models = {\n",
    "    \"XGBoost\": XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, max_depth=10),\n",
    "    \"LinearRegression\": LinearRegression()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 04:17:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Validation RMSE: 3.266006313997887\n",
      "Evaluating RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 04:17:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Validation RMSE: 3.3732701693315095\n",
      "Evaluating LinearRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 04:17:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression - Validation RMSE: 3.3685457926667777\n"
     ]
    }
   ],
   "source": [
    "# 2. Evaluate and log each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    val_rmse = evaluate_and_log_model(model, model_name, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    print(f\"{model_name} - Validation RMSE: {val_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic models\n",
    "models = {\n",
    "    \"XGBoost\": XGBRegressor(objective='reg:squarederror'),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [5, 10],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 10]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate models with GridSearchCV and log results to MLflow with a custom run name\n",
    "def evaluate_and_log_model_grid_search(model, model_name, param_grid, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # If no parameter grid for LinearRegression\n",
    "    if len(param_grid) == 0:\n",
    "        model_grid = model\n",
    "    else:\n",
    "        model_grid = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    # Create a custom run name using model name and the current date\n",
    "    run_name = f\"{model_name}_gridsearch_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    \n",
    "    start_time = time.time()  # Start time before training the model\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):  # Set the custom run name\n",
    "        # Train the model using GridSearchCV\n",
    "        model_grid.fit(X_train, y_train)\n",
    "        \n",
    "        end_time = time.time()  # End time after training the model\n",
    "        \n",
    "        # Get the best model from the grid search\n",
    "        best_model = model_grid.best_estimator_\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = best_model.predict(X_train)\n",
    "        y_pred_val = best_model.predict(X_val)\n",
    "        \n",
    "        # Calculate RMSE for train and validation sets\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "        \n",
    "        # Calculate RMSE for test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        \n",
    "        # Log parameters and metrics to MLflow\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        mlflow.log_params(model_grid.best_params_)\n",
    "        mlflow.log_metric('train_rmse', train_rmse)\n",
    "        mlflow.log_metric('val_rmse', val_rmse)\n",
    "        mlflow.log_metric('test_rmse', test_rmse)\n",
    "        mlflow.log_metric('elapsed_time', end_time - start_time)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Log the model (MLflow autologging will automatically log the model too)\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "        \n",
    "        return val_rmse  # Return validation RMSE for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost with GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 04:18:47 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2024/11/30 04:18:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Validation RMSE: 3.12416419883291\n",
      "Evaluating RandomForest with GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 04:19:09 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2024/11/30 04:19:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Validation RMSE: 2.9649778518309895\n"
     ]
    }
   ],
   "source": [
    "# 2. Evaluate and log each model using GridSearchCV\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} with GridSearchCV...\")\n",
    "    val_rmse = evaluate_and_log_model_grid_search(model, model_name, param_grids[model_name], X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    print(f\"{model_name} - Validation RMSE: {val_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log_arima(model, model_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Create a custom run name using model name and the current date\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):  # Set the custom run name\n",
    "        # Train the ARIMA model\n",
    "        arima_model = sm.tsa.ARIMA(y_train, order=(5,1,0))  # (p,d,q) parameters\n",
    "        arima_model_fit = arima_model.fit()\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = arima_model_fit.predict(start=0, end=len(y_train)-1)\n",
    "        y_pred_val = arima_model_fit.predict(start=len(y_train), end=len(y_train)+len(y_val)-1)\n",
    "        \n",
    "        # Calculate RMSE for train and validation sets\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "        \n",
    "        # Log parameters and metrics to MLflow\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        mlflow.log_metric('train_rmse', train_rmse)\n",
    "        mlflow.log_metric('val_rmse', val_rmse)\n",
    "        \n",
    "        # Log the ARIMA model parameters (order)\n",
    "        mlflow.log_param('arima_order', (5, 1, 0))  # The ARIMA order we used (p,d,q)\n",
    "        \n",
    "        # Serialize the ARIMA model using pickle\n",
    "        arima_model_filename = \"arima_model.pkl\"\n",
    "        with open(arima_model_filename, 'wb') as f:\n",
    "            pickle.dump(arima_model_fit, f)\n",
    "        \n",
    "        # Log the ARIMA model file as an artifact\n",
    "        mlflow.log_artifact(arima_model_filename)\n",
    "        \n",
    "        return val_rmse  # Return validation RMSE for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 18:04:30 WARNING mlflow.statsmodels: The fitted model is larger than 100 MB, saving it as artifacts is time consuming.\n",
      "To reduce model size, use `mlflow.statsmodels.autolog(log_models=False)` and manually log model by `mlflow.statsmodels.log_model(model, remove_data=True, artifact_path=\"model\")`\n",
      "2024/11/30 18:04:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.644412756002716"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_log_arima(None, \"ARIMA\", X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import log_param, log_metric\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def evaluate_and_log_arima(model_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Create a custom run name using model name and the current date\n",
    "    run_name = f\"{model_name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    \n",
    "    # Define the parameter grid for ARIMA (p, d, q)\n",
    "    param_grid = {\n",
    "        'p': [0, 1, 2, 3],   # Auto-regressive order\n",
    "        'd': [0, 1],         # Differencing order\n",
    "        'q': [0, 1, 2, 3]    # Moving average order\n",
    "    }\n",
    "    \n",
    "    best_val_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_arima_model_fit = None\n",
    "\n",
    "    # Iterate through all combinations of parameters\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        p, d, q = params['p'], params['d'], params['q']\n",
    "        \n",
    "        # Train the ARIMA model with the current combination of (p, d, q)\n",
    "        arima_model = sm.tsa.ARIMA(y_train, order=(p, d, q))\n",
    "        \n",
    "        # Fit the ARIMA model\n",
    "        arima_model_fit = arima_model.fit()\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = arima_model_fit.predict(start=0, end=len(y_train)-1)\n",
    "        y_pred_val = arima_model_fit.predict(start=len(y_train), end=len(y_train)+len(y_val)-1)\n",
    "        \n",
    "        # Calculate RMSE for train and validation sets\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "        \n",
    "        # Log parameters and metrics to MLflow\n",
    "        with mlflow.start_run(run_name=run_name):  # Set the custom run name\n",
    "            mlflow.log_param('model_name', model_name)\n",
    "            mlflow.log_param('arima_order', (p, d, q))  # Log current (p, d, q) values\n",
    "            mlflow.log_metric('train_rmse', train_rmse)\n",
    "            mlflow.log_metric('val_rmse', val_rmse)\n",
    "            \n",
    "            # Check if this model is the best one based on validation RMSE\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_params = (p, d, q)\n",
    "                best_arima_model_fit = arima_model_fit\n",
    "\n",
    "            print(f\"ARIMA ({p},{d},{q}) - Train RMSE: {train_rmse} | Validation RMSE: {val_rmse}\")\n",
    "    \n",
    "    # Log the best model and its parameters\n",
    "    if best_arima_model_fit:\n",
    "        best_run_name = f\"Best_ARIMA_{model_name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "        with mlflow.start_run(run_name=best_run_name):  # Log the best model\n",
    "            mlflow.log_param('best_arima_order', best_params)\n",
    "            mlflow.log_metric('best_val_rmse', best_val_rmse)\n",
    "            \n",
    "            # Serialize the best ARIMA model\n",
    "            arima_model_filename = \"best_arima_model.pkl\"\n",
    "            with open(arima_model_filename, 'wb') as f:\n",
    "                pickle.dump(best_arima_model_fit, f)\n",
    "            \n",
    "            # Log the best ARIMA model as an artifact\n",
    "            mlflow.log_artifact(arima_model_filename)\n",
    "            \n",
    "            print(f\"Best ARIMA model with order {best_params} - Validation RMSE: {best_val_rmse}\")\n",
    "    \n",
    "    return best_val_rmse  # Return the best validation RMSE for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ARIMA model evaluation\n",
    "evaluate_and_log_arima(\"ARIMA_Model\", X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Results: Random Forest\n",
    "* Best Hyperparameters:\n",
    "    * max_depth: 5\n",
    "    * n_estimators: 100\n",
    "\n",
    "* Random Forest Regressor model performed better based on the validation RMSE.\n",
    "    * Best max_depth: 5\n",
    "    * Best n_estimators: 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 04:51:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a813ab3b91e342c58624274bed8184fc', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legacy Monthly Model has been saved as 'legacy_monthly_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "best_max_depth = 5\n",
    "best_n_estimators = 100\n",
    "\n",
    "# Create the Random Forest model with the best hyperparameters\n",
    "legacy_monthly_model = RandomForestRegressor(n_estimators=best_n_estimators, \n",
    "                                             max_depth=best_max_depth, \n",
    "                                             random_state=42)\n",
    "\n",
    "# Train the model on the full training data\n",
    "legacy_monthly_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model as a pickle file\n",
    "with open(\"legacy_monthly_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(legacy_monthly_model, f)\n",
    "\n",
    "print(\"Legacy Monthly Model has been saved as 'legacy_monthly_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler has been saved as 'scaler.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# save the scaler\n",
    "\n",
    "with open(\"scaler.pkl\", 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "print(\"Scaler has been saved as 'scaler.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Monthly EXP Done ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Sales Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20642, 11) (111, 11) (4239, 11)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - creating lag features\n",
    "def create_lag_features(df, target_column, lags=[1, 2, 3, 6, 12]):\n",
    "    \"\"\"\n",
    "    Creates lag features for a given target column.\n",
    "    \"\"\"\n",
    "    for lag in lags:\n",
    "        df[f'{target_column}_lag_{lag}'] = df.groupby(['shop_id', 'item_id'])[target_column].shift(lag)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply lag features for 'item_cnt_month_diff' and 'item_cnt_day_diff'\n",
    "train = create_lag_features(train, 'item_cnt_day_diff')\n",
    "validation = create_lag_features(validation, 'item_cnt_day_diff')\n",
    "test = create_lag_features(test, 'item_cnt_day_diff')\n",
    "\n",
    "# Features for the model\n",
    "features = ['year', 'month', 'date_block_num', 'shop_id', 'item_id', 'item_price'] + \\\n",
    "           [f'item_cnt_day_diff_lag_{lag}' for lag in [1, 2, 3, 6, 12]]\n",
    "\n",
    "# Targets\n",
    "target = 'item_cnt_day_diff'\n",
    "\n",
    "# Define X and y for training, validation, and test datasets\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = validation[features]\n",
    "y_val = validation[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "# Verify the shapes after scaling\n",
    "print(X_train_scaled.shape, X_val_scaled.shape, X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 04:59:54 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.4.2 <= xgboost <= 2.1.2, but the installed version is 2.1.3. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n",
      "2024/11/30 04:59:54 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"daily_sales_forecasting\"\n",
    "# Set the new experiment\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.sklearn.autolog()\n",
    "mlflow.xgboost.autolog()\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic models\n",
    "models = {\n",
    "    \"XGBoost\": XGBRegressor(objective='reg:squarederror'),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [5, 10],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 10]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (78328,)\n",
      "y_val shape: (111,)\n",
      "y_test shape: (4239,)\n"
     ]
    }
   ],
   "source": [
    "# Before evaluating, check the shapes of your datasets\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost with GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 05:00:09 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2024/11/30 05:00:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Validation RMSE: 604.8419631615602\n",
      "Evaluating RandomForest with GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 05:00:37 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2024/11/30 05:00:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Validation RMSE: 600.3716826937632\n"
     ]
    }
   ],
   "source": [
    "# 2. Evaluate and log each model using GridSearchCV\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} with GridSearchCV...\")\n",
    "    val_rmse = evaluate_and_log_model_grid_search(model, model_name, param_grids[model_name], X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    print(f\"{model_name} - Validation RMSE: {val_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ARIMA model evaluation\n",
    "\n",
    "evaluate_and_log_arima(\"ARIMA_Model\", X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlusion :\n",
    "\n",
    "Based on the results of ML Models and DL Models like Arima, we have seen poor predicting and forecasting perfomance so we conclude that we will just work with monthly predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
